<html>
	<head>
	{% include "basic/includes.html" %}

	</head>
	
	<body>
		{% include "basic/header.html" %}
		<div class="container-sm">
			<div class="row">
				<div class="col-md-8">
					<div class="shadow container bg-light mb-5">
						<div class="row">
							<div class="container px-4 pt-3 pb-4">
								<div class="row">
									<div class="col">
										<h2>End-to-End Automatic Speech Recognition based on Hybrid CTC/Attention mechanism</h2>
										<a target="_blank" href="https://github.com/mayank-git-hub/ETE-Speech-Recognition"><img class="px-4 pt-4 mb-4" src="/static/Images/Content/ETE/ETE.png" width="100%"></a>
										<p>Last Updated: 5th May</p>
										<p>Reimplemented the paper <a target="_blank" href="https://ieeexplore.ieee.org/document/8068205">Hybrid CTC/Attention Architecture for End-to-End Speech Recognition</a> in pure python and PyTorch. Earlier implementation existed on <a target="_blank" href="https://github.com/espnet/espnet">ESPNET</a> but the pre-processing step uses Kaldi which is written in C++. Also the pipeline seemed complicated for people looking for just training and implementing the ASR. The code is available on github.</p>
										<a target="_blank" href="https://github.com/mayank-git-hub/ETE-Speech-Recognition"><button type="button" class="btn btn-light btn-outline-dark">GitHub Implementation</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<a target="_blank" href="https://www.primeacademypune.com"><img class="px-4 pt-4" src="/static/Images/Content/PrimeAcademy/PrimeAcademy.png" width="100%"></a>
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Web Development</h2>
										<p>Last Updated: 26th April</p>
										<p>The website <a target="_blank" href="https://www.primeacademypune.com">https://www.primeacademypune.com <i class="fa fa-external-link"></i></a> was created by me using pure html, css and javascript for the client side and Django for the server side. The server was deployed on Amazon Web Services. I also deployed moodle on AWS and hosted it on <a target="_blank" href="https://online.primeacademypune.com">https://online.primeacademypune.com <i class="fa fa-external-link"></i></a></p>
									</div>s
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/HyperSpectral/joined.jpg" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Hyperspectral Tissue Image Segmentation and classification</h2>
										<p>Last Updated: 26th April</p>
										<p>Given a tissue Hyperspectral image it is very time consuming for the doctors to annotate the epithilium, stromal and goblet cells. So we tried to automate this process. We used Non Negative Matrix Factorisation (NMF) and Semi Supervised NMF (SSNMF) for dimentionality reduction because the spectra contained too much redundant data. Then using different classifiers like SVM, NN, and Random Forest we tried to classify each and every pixel. Then we moved on to using spatial information by taking windows of different length. This improved the accuracy by 2-3 percent. Using Regularisation in NN we could further increase the accuracy by 2-3 percent. </p>
									</div>s
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/IDRiD/IDRiD.png" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Diabetic Retinopathy Lesion Segmentation</h2>
										<p>Last Updated: 26th April</p>
										<p>Due to the advances in Medical science it has become possible to detect Diabetic Retinopathy at an early stage. But due to unavailability of the humongous number of doctors required for reliable diagnosis, and the increasing number of Diabetes affected people, there is a high requirement for automation. We tried to approach the challenge of automating the segmentation of different type of lesions like Microaneurysms, Haemorrhage, Soft and Hard Exudates using a new novel architecture of Fusion Net.</p>
										<a target="_blank" href="/static/pdf/ISBI2018.pdf"><button type="button" class="btn btn-light btn-outline-dark">Read the paper</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/TextDetectionCRAFT/craft_example.gif" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>CRAFT Text-Detection</h2>
										<p>Last Updated: 26th April</p>
										<p>Traditional Text Detection methods have used word-level bounding boxes for target and getting true positives. Character-Region Awareness For Text-Detection (CRAFT) uses weak-supervision for predicting character level predictions using word-level annotation. This is achieved by first training the model on a Synthetic Dataset and then fine-tuning it on a real dataset and using the transcriptions to get the character predictions.<br> The full method can be understood in <a href="https://arxiv.org/abs/1904.01941"> the original paper </a>. I reimplemented the training of CRAFT on github.</p>
										<a target="_blank" href="http://github.com/autonise/craft-remade.git"><button type="button" class="btn btn-light btn-outline-dark">GitHub Implementation</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/TextDetectionPixelLink/Pixel-Link.png" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Pixel-Link Text Detection</h2>
										<p>Last Updated: 26th April</p>
										<p>Traditional Text-Detection methods have focused on bounding box regression to detect text in real images. This inherently has many problems like curved text, aspect-ratio sensitivity of regression models, density of predictions and so on. Pixel-Link treats text-detection as a pixel level instance segmentation problem with each pixel being clubbed to its neighbouring pixel if joined by a "link" which is also predicted by the model. For more in-depth analysis you can read the paper on <a href="https://arxiv.org/pdf/1801.01315.pdf">Link to Paper</a>. I reimplemented Pixel-Link on github.</p>
										<a target="_blank" href="http://github.com/autonise/Text-Recognition.git"><button type="button" class="btn btn-light btn-outline-dark">GitHub Implementation</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/PingPong/ping_pong.png" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Ping - Pong</h2>
										<p>Last Updated: 26th April</p>
										<p>I thought of implementing the basics of reinforcement learning and convolutional neural networks for training a neural network to predict the movement of the bat to reflect back the ball. I implemented the entire graphical interface using basic python and numpy array and the code for the same has been uploaded on git-hub for reference. </p>
										<a target="_blank" href="https://github.com/mayank-git-hub/Ping_pong"><button type="button" class="btn btn-light btn-outline-dark">GitHub Implementation</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/ImageStitching/imagestitch.jpg" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Image Stitching</h2>
										<p>Last Updated: 26th April</p>
										<p>The task was to stitch a heavily blurred frames of a video to get the entire image of the tissue because the microscope can only see a limited part of it at a time. The project is really challenging in the aspect that there is some random noise, some smudge on the lens of the microscope, the image is heavily blurred and also the brightness has been autoadjusted in input. A challenging but a fruitfull process for applying the things I have learnt in signals and systems.</p>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/Socket/socket.jpg" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>Socket Programming</h2>
										<p>Last Updated: 26th April</p>
										<p>Due to severe lack of funds (Well I spent all the money on eating :p) I wanted to use the inbuilt camera in my laptop for my Real Time Face detection project. Also having learnt socket programming recently in my CS 224 minor, I thought why not implement it. So Using python I made a server and client program to send the images as bytes and to reconstruct those images on my PC. I sent the data using UDP as I needed fast response rather than reliability. For increasing the transfer speed and using less bandwidth, I first convert the images to JPEG format and then send the bytes and decode on the other side as a numpy image which saves the bandwidth upto 40 times. The implementation has been uploaded on github.</p>
										<a target="_blank" href="https://github.com/mayank-git-hub/VideoTransfer"><button type="button" class="btn btn-light btn-outline-dark">GitHub Implementation</button></a>
									</div>
								</div>
							</div>
						</div>
					</div>

					<div class="shadow container bg-light mb-5">
						<div class="row">
							<img class="px-4 pt-4" src="/static/Images/Content/RSA/encry.jpg" width="100%">
							<div class="container px-4 pt-5 pb-4">
								<div class="row">
									<div class="col">
										<h2>RSA key encryption</h2>
										<p>Last Updated: 26th April</p>
										<p>
											Wouldn't it be ideal if nobody stole anything in this world nor had any malicious intent? Well we do not live in such an idealized world. So to Save my projects from all those trying to steal it, I made an RSA file encryption program. The basics are simple, the implementation not so.
										</p>
										<p> How it works??</p>
										<p>
										   So suppose Cooper wants to send a message to Murph from some other Galaxy. But there are some aliens trying to intercept this message. So first Cooper tells Murph, "Hey I want to send a message to you". Then Murph sends a public key to Cooper. But these aliens in between also intercept this key. They are like "Haha, whatever you send will be recieved by us. Even if you send a way to change code, we will understand it" Obviously Cooper does not know whether the key has been seen by the aliens or not. He used the public key and encodes the entire message and sends it to Murph. And alas the aliens get the message. But wait, it is gibberish. And even though they are giving it their all, they can't seem to use the public key to decode the message.
										</p>
										<p>
										   The message goes to Murph and Murph too recieves some gibberish message. Now how will she decode this message?? Well she has an advantage over the aliens. She has a private key which enables her to decode the message easily. This is how any encryption works in principle.<br>	
										</p>
									</div>
								</div>
							</div>
						</div>
					</div>

				</div>
				{% include "basic/intro.html" %}
			</div>
		</div>
		
	</body>
	
</html>